# -*- coding: utf-8 -*-
"""
Website link: https://tf.wiki/zh/basic/models.html

Created on Sat Dec 28 19:16:55 2019

@author: liujie
"""
import tensorflow as tf
import numpy as np

#-----------------------------å®šä¹‰ä¸€äº›æ¨¡å‹è¶…å‚æ•°------------------------------
# è¿™äº›å‚æ•°éƒ½ä¼šå½±å“æ¨¡å‹æ€§èƒ½
num_epochs = 5
batch_size = 50 #æ‰¹æ¬¡å¤§å°å½±å“æ¨¡å‹æ€§èƒ½ï¼Œå°ä¸€ç‚¹ä¼šæ›´å¥½
learning_rate = 0.01

#-----------------------------æ•°æ®è·å–åŠé¢„å¤„ç†------------------------------
#tf.keras.datasets
#æ•°æ®å‡†å¤‡æ–¹å¼å½±å“è®¡ç®—é€Ÿåº¦
class MNISTLoader():
    def __init__(self):
        mnist = tf.keras.datasets.mnist
        (self.train_data, self.train_label), (self.test_data, self.test_label) = mnist.load_data()
        # MNISTä¸­çš„å›¾åƒé»˜è®¤ä¸ºuint8ï¼ˆ0-255çš„æ•°å­—ï¼‰ã€‚ä»¥ä¸‹ä»£ç å°†å…¶å½’ä¸€åŒ–åˆ°0-1ä¹‹é—´çš„æµ®ç‚¹æ•°ï¼Œå¹¶åœ¨æœ€åå¢åŠ ä¸€ç»´ä½œä¸ºé¢œè‰²é€šé“
        self.train_data = np.expand_dims(self.train_data.astype(np.float32) / 255.0, axis=-1)      # [60000, 28, 28, 1]
        self.test_data = np.expand_dims(self.test_data.astype(np.float32) / 255.0, axis=-1)        # [10000, 28, 28, 1]
        self.train_label = self.train_label.astype(np.int32)    # [60000]
        self.test_label = self.test_label.astype(np.int32)      # [10000]
        self.num_train_data, self.num_test_data = self.train_data.shape[0], self.test_data.shape[0]

    def get_batch(self, batch_size):
        # ä»æ•°æ®é›†ä¸­éšæœºå–å‡ºbatch_sizeä¸ªå…ƒç´ å¹¶è¿”å›
        index = np.random.randint(0, np.shape(self.train_data)[0], batch_size)
        return self.train_data[index, :], self.train_label[index]


#-----------------------------æ¨¡å‹çš„æ„å»º------------------------------
#ï¼š tf.keras.Model å’Œ tf.keras.layers
# æ¨¡å‹çš„è®¾è®¡å½±å“æ¨¡å‹çš„æ€§èƒ½
class CNN(tf.keras.Model):
    def __init__(self):
        super().__init__()
        self.conv1 = tf.keras.layers.Conv2D(
            filters=32,             # å·ç§¯å±‚ç¥ç»å…ƒï¼ˆå·ç§¯æ ¸ï¼‰æ•°ç›®
            kernel_size=[5, 5],     # æ„Ÿå—é‡å¤§å°
            padding='same',         # paddingç­–ç•¥ï¼ˆvaild æˆ– sameï¼‰
            activation=tf.nn.relu   # æ¿€æ´»å‡½æ•°
        )
        self.pool1 = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2)
        self.conv2 = tf.keras.layers.Conv2D(
            filters=64,
            kernel_size=[5, 5],
            padding='same',
            activation=tf.nn.relu
        )
        self.pool2 = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2)
        self.flatten = tf.keras.layers.Reshape(target_shape=(7 * 7 * 64,))
        self.dense1 = tf.keras.layers.Dense(units=1024, activation=tf.nn.relu)
        self.dense2 = tf.keras.layers.Dense(units=10)

    def call(self, inputs):
        x = self.conv1(inputs)                  # [batch_size, 28, 28, 32]
        x = self.pool1(x)                       # [batch_size, 14, 14, 32]
        x = self.conv2(x)                       # [batch_size, 14, 14, 64]
        x = self.pool2(x)                       # [batch_size, 7, 7, 64]
        x = self.flatten(x)                     # [batch_size, 7 * 7 * 64]
        x = self.dense1(x)                      # [batch_size, 1024]
        x = self.dense2(x)                      # [batch_size, 10]
        output = tf.nn.softmax(x)
        return output


#-----------------------------å®ä¾‹åŒ–æ¨¡å‹å’Œæ•°æ®è¯»å–ç±»------------------------------
#å¹¶å®ä¾‹åŒ–ä¸€ä¸ª tf.keras.optimizer çš„ä¼˜åŒ–å™¨ï¼ˆè¿™é‡Œä½¿ç”¨å¸¸ç”¨çš„ Adam ä¼˜åŒ–å™¨ï¼‰
model = CNN()
data_loader = MNISTLoader()

# ä¼˜åŒ–å™¨optimizerçš„ä½œç”¨ï¼šæ ¹æ®learning_rate(ğœ‚)å’Œloss(ğ¿)è®¡ç®—æ¨¡å‹å‚æ•°ã€‚æ¨¡å‹çš„åˆå§‹å‚æ•°w0æ˜¯éšæœºç»™å®šçš„ã€‚
# å³ï¼Œw = optimizer (ğ¿,ğœ‚,w0)
# ä¼˜åŒ–å™¨optimizeråœ¨å·¥ä½œè¿‡ç¨‹ä¸­ï¼Œå®ƒè¿˜ä¼šéšç€è¿­ä»£epochè€Œè°ƒæ•´å­¦ä¹ ç‡learning_rate(ğœ‚)ã€‚æ€è·¯æ˜¯ï¼š
# åˆå§‹é˜¶æ®µå§‹é€‰æ‹©å¤§çš„ğœ‚=ğœ‚0(å³åˆå§‹ğœ‚)ï¼Œéšç€è¿­ä»£çš„æ·±å…¥ï¼Œç”±äºæˆ‘ä»¬åœ¨æ¥è¿‘å±€éƒ¨æˆ–è€…å…¨å±€æœ€ä¼˜loss(ğ¿)ï¼Œæˆ‘ä»¬è°ƒå°ğœ‚ã€‚
# å› æ­¤ï¼Œé€‰æ‹©ä»€ä¹ˆæ ·çš„ä¼˜åŒ–å™¨å†³å®šäº†ğœ‚è°ƒæ•´çš„å¥½åã€‚æœ‰çš„ä¼˜åŒ–å™¨æ–¹æ³•è¿˜æ¶‰åŠåˆ°åŠ¨é‡Momentumçš„è®¾å®šã€‚
# ä¼˜åŒ–å™¨å‡½æ•°optimizerå’ŒæŸå¤±å‡½æ•°lossä¸€èµ·å½±å“æ¨¡å‹æ€§èƒ½ï¼Œlosså‡½æ•°æ˜¯ä¼˜åŒ–å™¨å‡½æ•°optimizerçš„ä¸Šæ¸¸ã€‚
optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)

#-----------------------------è¿­ä»£è®­ç»ƒæ¨¡å‹------------------------------
#ç„¶åè¿­ä»£è¿›è¡Œä»¥ä¸‹æ­¥éª¤ï¼š

#ä» DataLoader ä¸­éšæœºå–ä¸€æ‰¹è®­ç»ƒæ•°æ®ï¼›

#å°†è¿™æ‰¹æ•°æ®é€å…¥æ¨¡å‹ï¼Œè®¡ç®—å‡ºæ¨¡å‹çš„é¢„æµ‹å€¼ï¼›

#å°†æ¨¡å‹é¢„æµ‹å€¼ä¸çœŸå®å€¼è¿›è¡Œæ¯”è¾ƒï¼Œè®¡ç®—æŸå¤±å‡½æ•°ï¼ˆlossï¼‰ã€‚è¿™é‡Œä½¿ç”¨ tf.keras.losses ä¸­çš„äº¤å‰ç†µå‡½æ•°ä½œä¸ºæŸå¤±å‡½æ•°ï¼›

#è®¡ç®—æŸå¤±å‡½æ•°å…³äºæ¨¡å‹å˜é‡çš„å¯¼æ•°ï¼›

#å°†æ±‚å‡ºçš„å¯¼æ•°å€¼ä¼ å…¥ä¼˜åŒ–å™¨ï¼Œä½¿ç”¨ä¼˜åŒ–å™¨çš„ apply_gradients æ–¹æ³•æ›´æ–°æ¨¡å‹å‚æ•°ä»¥æœ€å°åŒ–æŸå¤±å‡½æ•°

num_batches = int(data_loader.num_train_data // batch_size * num_epochs)


for batch_index in range(num_batches):
    X, y = data_loader.get_batch(batch_size)
    # 1.å¼€å§‹æ‰§è¡Œæ¢¯åº¦ä¸‹é™ï¼ˆGradient Descentï¼‰ï¼Œè¿‡ç¨‹ä¸­è®¡ç®—loss
    with tf.GradientTape() as tape:
        # 2.éšæœºèµ‹å€¼æ¨¡å‹çš„å‚æ•°wï¼Œè®¡ç®—loss
        y_pred = model(X)
        # 2.1 é‡‡ç”¨äº¤å‰ç†µcrossentropyæ–¹æ³•è®¡ç®—lossã€‚åˆé€‚çš„lossè®¡ç®—æ–¹å¼å†³å®šæ¨¡å‹æ€§èƒ½ã€‚
        loss = tf.keras.losses.sparse_categorical_crossentropy(y_true=y, y_pred=y_pred)
        loss = tf.reduce_mean(loss)
        print("batch %d: loss %f" % (batch_index, loss.numpy()))
    # 3.æ ¹æ®æ‰€å¾—loss(ğ¿)ï¼Œè®¡ç®—å¯¼æ•°ğœ•ğ¿/ğœ•ğ‘¤
    grads = tape.gradient(loss, model.variables)
    # 4.ä¾æ®#3æ‰€å¾—å¯¼æ•°ï¼Œå’Œå­¦ä¹ ç‡learning_rate(ğœ‚)ï¼Œå¾—å‡ºä¸‹ä¸€æ­¥çš„æ¨¡å‹çš„å‚æ•°ï¼šğ‘¤ â† ğ‘¤ âˆ’ ğœ‚ğœ•ğ¿/ğœ•ğ‘¤
    optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))
 
    
#----------------------------------------------æ¨¡å‹çš„è¯„ä¼°------------------------------
#tf.keras.metrics
sparse_categorical_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()
num_batches = int(data_loader.num_test_data // batch_size)
for batch_index in range(num_batches):
    start_index, end_index = batch_index * batch_size, (batch_index + 1) * batch_size
    y_pred = model.predict(data_loader.test_data[start_index: end_index])
    sparse_categorical_accuracy.update_state(y_true=data_loader.test_label[start_index: end_index], y_pred=y_pred)
print("test accuracy: %f" % sparse_categorical_accuracy.result())
